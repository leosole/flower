{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Tja2N6l-qH-e"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import flwr as fl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import ray\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FraudDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J4Em7BPNTXeX"
      },
      "outputs": [],
      "source": [
        "client1_args = {\n",
        "    'train_split': 2000, 'initial_split': 1, 'test_split': 3000, 'batch_size': 32, 'label': 30, 'columns': [*range(0,25)]\n",
        "}\n",
        "client2_args = {\n",
        "    'train_split': 5000, 'initial_split': 3000, 'test_split': 6000, 'batch_size': 32, 'label': 30, 'columns': [*range(5,30)]\n",
        "}\n",
        "\n",
        "def load_data(path, initial_split, train_split, test_split, columns, batch_size=32, label=30): # \"data/creditcard.csv\", 2000, 3000, 1:30\n",
        "  df = pd.read_csv(path)\n",
        "  x_train = df.iloc[initial_split:train_split, columns].values\n",
        "  y_train = df.iloc[initial_split:train_split, label].values\n",
        "  sc = StandardScaler()\n",
        "  x_train = sc.fit_transform(x_train)\n",
        "  x_test = df.iloc[train_split:test_split, columns].values\n",
        "  x_test = sc.transform(x_test)\n",
        "  y_test = df.iloc[train_split:test_split, label].values\n",
        "  trainset = FraudDataset(x_train, y_train)\n",
        "  testset = FraudDataset(x_test, y_test)\n",
        "  trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "  valloader = DataLoader(testset, batch_size=batch_size)\n",
        "  return trainloader, valloader\n",
        "\n",
        "train1, test1 = load_data(\"data/creditcard.csv\", **client1_args)\n",
        "train2, test2 = load_data(\"data/creditcard.csv\", **client2_args)\n",
        "\n",
        "trainloaders = [train1, train2]\n",
        "valloaders = [test1, test2]\n",
        "shared_columns = [col for col in client1_args['columns'] if col in client2_args['columns']]\n",
        "client1_args['ind_columns'] = [col for col in client1_args['columns'] if col not in shared_columns]\n",
        "client2_args['ind_columns'] = [col for col in client2_args['columns'] if col not in shared_columns]\n",
        "args = [client1_args, client2_args]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(shared_model, ind_model, agg_model, shared_opt, ind_opt, agg_opt, trainloader, epochs, ind_columns):\n",
        "    criterion = nn.BCELoss()\n",
        "    for _ in range(epochs):\n",
        "        for x, y in trainloader:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            print(x[shared_columns].size())\n",
        "            shared_opt.zero_grad()\n",
        "            ind_opt.zero_grad()\n",
        "            agg_opt.zero_grad()\n",
        "            shared_outputs = shared_model(x[shared_columns])\n",
        "            ind_outputs = ind_model(x[ind_columns])\n",
        "            outputs = agg_model(torch.cat((shared_outputs, ind_outputs), dim=1))\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            shared_outputs.sum().backward()\n",
        "            ind_outputs.sum().backward()\n",
        "            shared_opt.step()\n",
        "            ind_opt.step()\n",
        "            agg_opt.step()\n",
        "\n",
        "def test(shared_model, ind_model, agg_model, valloader, ind_columns):\n",
        "    \"\"\"Validate the modelwork on the entire test set.\"\"\"\n",
        "    criterion = nn.BCELoss()\n",
        "    loss = 0.0\n",
        "    tp, fp, tn, fn = 0, 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in valloader:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            print(x[shared_columns].size())\n",
        "            shared_outputs = shared_model(x[shared_columns])\n",
        "            ind_outputs = ind_model(x[ind_columns])\n",
        "            outputs = agg_model(torch.cat((shared_outputs, ind_outputs), dim=1))\n",
        "            loss += criterion(outputs, y).item()\n",
        "            pred = round(float(outputs.get()[0]))\n",
        "            lab = float(y.get()[0])\n",
        "            # Collect statistics\n",
        "            tp += (pred and lab)\n",
        "            fp += (pred and not lab)\n",
        "            tn += (not pred and not lab)\n",
        "            fn += (not pred and lab)\n",
        "    f1_score = tp / (tp + (fp + fn)/2)\n",
        "    return loss, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1ZxGk6AMNvvV"
      },
      "outputs": [],
      "source": [
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ye6Jt5p3LWtF"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, shared_model, trainloader, valloader, ind_model, agg_model, shared_opt, ind_opt, agg_opt, columns):\n",
        "        self.shared_model = shared_model\n",
        "        self.ind_model = ind_model\n",
        "        self.agg_model = agg_model\n",
        "        self.shared_opt = shared_opt\n",
        "        self.ind_opt = ind_opt\n",
        "        self.agg_opt = agg_opt\n",
        "        self.trainloader = trainloader\n",
        "        self.columns = columns\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self):\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.shared_model, parameters)\n",
        "        train(self.shared_model, self.ind_model, self.agg_model, self.shared_opt, self.ind_opt, self.agg_opt, self.trainloader, 1, self.columns)\n",
        "        return get_parameters(self.shared_model), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.shared_model, parameters)\n",
        "        loss, f1_score = test(self.shared_model, self.ind_model, self.agg_model, self.valloader, self.columns)\n",
        "        return float(loss), len(self.valloader), {\"f1_score\": float(f1_score)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SplitNN(nn.Module):\n",
        "    def __init__(self, sizes) -> None:\n",
        "        super(SplitNN, self).__init__()\n",
        "        self.input_size = sizes[0]\n",
        "        self.output_size = sizes[-1]\n",
        "        self.lin1 = nn.Linear(sizes[0], sizes[1])\n",
        "        self.lin2 = nn.Linear(sizes[1], sizes[2])\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = torch.sigmoid(x) if self.output_size == 1 else x\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qkcwggRYOwWN"
      },
      "outputs": [],
      "source": [
        "def client_fn(cid: str) -> FlowerClient:\n",
        "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
        "    print(f'Creating client {cid}')\n",
        "    # Load model\n",
        "    shared_model = SplitNN([len(shared_columns), 64, 32])\n",
        "    ind_model = SplitNN([len(args[int(cid)]['ind_columns']), 32, 32])\n",
        "    agg_model = SplitNN([64, 16, 1])\n",
        "    shared_opt = torch.optim.SGD(shared_model.parameters(), lr=0.001, momentum=0.9)\n",
        "    ind_opt = torch.optim.SGD(ind_model.parameters(), lr=0.001, momentum=0.9)\n",
        "    agg_opt = torch.optim.SGD(agg_model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "\n",
        "    # Create a  single Flower client representing a single organization\n",
        "    return FlowerClient(shared_model, trainloader, valloader, ind_model, agg_model, shared_opt, ind_opt, agg_opt, args[int(cid)]['ind_columns'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ELNy0-0nfyI2"
      },
      "outputs": [],
      "source": [
        "# Create FedAvg strategy\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "        fraction_fit=1.0,  # Sample 100% of available clients for training\n",
        "        fraction_eval=0.5,  # Sample 50% of available clients for evaluation\n",
        "        min_fit_clients=2,  # Never sample less than 10 clients for training\n",
        "        min_eval_clients=1,  # Never sample less than 5 clients for evaluation\n",
        "        min_available_clients=2,  # Wait until all 10 clients are available\n",
        ")\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=2,\n",
        "    num_rounds=5,\n",
        "    strategy=strategy,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Flower-1-Intro-to-FL-PyTorch.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
